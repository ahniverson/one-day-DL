{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hukim1112/one-day-DL/blob/main/(pytorch)MPG_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIdT9iu_Z4Rb"
      },
      "source": [
        "# 자동차 연비 예측하기: 회귀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHp3M9ZmrIxj"
      },
      "source": [
        "*회귀*(regression)는 가격이나 확률 같이 연속된 출력 값을 예측하는 것이 목적입니다. 이와는 달리 *분류*(classification)는 여러개의 클래스 중 하나의 클래스를 선택하는 것이 목적입니다(예를 들어, 사진에 사과 또는 오렌지가 포함되어 있을 때 어떤 과일인지 인식하는 것).\n",
        "\n",
        "이 노트북은 [Auto MPG](https://archive.ics.uci.edu/ml/datasets/auto+mpg) 데이터셋을 사용하여 1970년대 후반과 1980년대 초반의 자동차 연비를 예측하는 모델을 만듭니다. 이 기간에 출시된 자동차 정보를 모델에 제공하겠습니다. 이 정보에는 실린더 수, 배기량, 마력(horsepower), 공차 중량 같은 속성이 포함됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_72b0LCNbjx"
      },
      "source": [
        "## Auto MPG 데이터셋\n",
        "\n",
        "이 데이터셋은 [UCI 머신 러닝 저장소](https://archive.ics.uci.edu/ml/)에서 다운로드할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFh9ne3FZ-On"
      },
      "source": [
        "### 데이터 구하기\n",
        "먼저 데이터셋을 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9kxxgzvzlyz"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "dataset_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nslsRLh7Zss4"
      },
      "source": [
        "판다스를 사용하여 데이터를 읽습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiX2FI4gZtTt"
      },
      "outputs": [],
      "source": [
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MWuJTKEDM-f"
      },
      "source": [
        "### 데이터 정제하기\n",
        "\n",
        "이 데이터셋은 일부 데이터가 누락되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEJHhN65a2VV"
      },
      "outputs": [],
      "source": [
        "dataset.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UPN0KBHa_WI"
      },
      "source": [
        "문제를 간단하게 만들기 위해서 누락된 행을 삭제하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZUDosChC1UN"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XKitwaH4v8h"
      },
      "source": [
        "`\"Origin\"` 열은 수치형이 아니고 범주형이므로 원-핫 인코딩(one-hot encoding)으로 변환하겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWNTD2QjBWFJ"
      },
      "outputs": [],
      "source": [
        "origin = dataset.pop('Origin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulXz4J7PAUzk"
      },
      "outputs": [],
      "source": [
        "dataset['USA'] = (origin == 1)*1.0\n",
        "dataset['Europe'] = (origin == 2)*1.0\n",
        "dataset['Japan'] = (origin == 3)*1.0\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cuym4yvk76vU"
      },
      "source": [
        "### 데이터셋을 훈련 세트와 테스트 세트로 분할하기\n",
        "\n",
        "이제 데이터를 훈련 세트와 테스트 세트로 분할합니다.\n",
        "\n",
        "테스트 세트는 모델을 최종적으로 평가할 때 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn-IGhUE7_1H"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi2FzC3T21jR"
      },
      "outputs": [],
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop(\"MPG\")\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db7Auq1yXUvh"
      },
      "source": [
        "### 특성과 레이블 분리하기\n",
        "\n",
        "특성에서 타깃 값 또는 \"레이블\"을 분리합니다. 이 레이블을 예측하기 위해 모델을 훈련시킬 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2sluJdCW7jN"
      },
      "outputs": [],
      "source": [
        "train_labels = train_dataset.pop('MPG')\n",
        "test_labels = test_dataset.pop('MPG')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRklxK5s388r"
      },
      "source": [
        "### 데이터 정규화\n",
        "\n",
        "위 `train_stats` 통계를 다시 살펴보고 각 특성의 범위가 얼마나 다른지 확인해 보죠."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ywmerQ6dSox"
      },
      "source": [
        "특성의 스케일과 범위가 다르면 정규화(normalization)하는 것이 권장됩니다. 특성을 정규화하지 않아도 모델이 *수렴할 수 있지만*, 훈련시키기 어렵고 입력 단위에 의존적인 모델이 만들어집니다.\n",
        "\n",
        "노트: 의도적으로 훈련 세트만 사용하여 통계치를 생성했습니다. 이 통계는 테스트 세트를 정규화할 때에도 사용됩니다. 이는 테스트 세트를 모델이 훈련에 사용했던 것과 동일한 분포로 투영하기 위해서입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlC5ooJrgjQF"
      },
      "outputs": [],
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuiClDk45eS4"
      },
      "source": [
        "정규화된 데이터를 사용하여 모델을 훈련합니다.\n",
        "\n",
        "주의: 여기에서 입력 데이터를 정규화하기 위해 사용한 통계치(평균과 표준편차)는 원-핫 인코딩과 마찬가지로 모델에 주입되는 모든 데이터에 적용되어야 합니다. 여기에는 테스트 세트는 물론 모델이 실전에 투입되어 얻은 라이브 데이터도 포함됩니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.values.shape"
      ],
      "metadata": {
        "id": "m6u3M4pJZXgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "#torch 데이터셋을 먼저 구축합니다.\n",
        "train_dataset = TensorDataset(torch.tensor(normed_train_data.values, dtype=torch.float32), torch.tensor(train_labels.values.reshape(-1,1), dtype=torch.float32))\n",
        "test_dataset = TensorDataset(torch.tensor(normed_test_data.values, dtype=torch.float32), torch.tensor(test_labels.values.reshape(-1,1), dtype=torch.float32))"
      ],
      "metadata": {
        "id": "1eRddtxYY5T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#torch 데이터로더를 구축합니다. 배치사이즈는 512개, 학습셋은 shuffe해줍니다.\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "v7QDyRw-ZvrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i6cZ1_W1eUSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmjdzxKzEu1-"
      },
      "source": [
        "## 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SWtkIjhrZwa"
      },
      "source": [
        "### 모델 만들기\n",
        "\n",
        "모델을 구성해 보죠. 여기에서는 두 개의 완전 연결(densely connected) 은닉층으로 `Sequential` 모델을 만들겠습니다. 출력 층은 하나의 연속적인 값을 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c26juK7ZG8j-"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class MPGregression(nn.Module):\n",
        "    def __init__(self, input_dims):\n",
        "        super().__init__()\n",
        "        self.fcn = nn.Sequential(\n",
        "            nn.Linear(input_dims, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.fcn(x)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[torchmetrics](https://torchmetrics.readthedocs.io/en/stable/classification/accuracy.html)의 metric api를 사용해서 예측과 정답으로 accuracy나 mse, mae 등을 쉽게 계산하고, 그들의 누적값을 계산할 수 있습니다."
      ],
      "metadata": {
        "id": "pwm3KfiVy7la"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGbPb-PHGbhs"
      },
      "outputs": [],
      "source": [
        "from torchmetrics import MeanSquaredError, MeanAbsoluteError\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "def train_epoch(dataloader, model, loss_fn, optimizer):\n",
        "    mse  = MeanSquaredError().to(device)\n",
        "    mae  = MeanAbsoluteError().to(device)\n",
        "    model.train()\n",
        "    total_loss, correct = 0, 0\n",
        "    for batch, (X,y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device) #샘플과 정답을 GPU로 전달\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred,y)\n",
        "        mse(pred, y)\n",
        "        mae(pred, y)\n",
        "\n",
        "        #Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return mse.compute(), mae.compute()  #mse, mae\n",
        "\n",
        "def test_epoch(dataloader, model, loss_fn):\n",
        "    mse  = MeanSquaredError().to(device)\n",
        "    mae  = MeanAbsoluteError().to(device)\n",
        "    model.eval()\n",
        "    total_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch, (X,y) in enumerate(dataloader):\n",
        "            X, y = X.to(device), y.to(device) #샘플과 정답을 GPU로 전달\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred,y)\n",
        "            mse(pred, y)\n",
        "            mae(pred, y)\n",
        "    return mse.compute(), mae.compute()  #mse, mae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj49Og4YGULr"
      },
      "source": [
        "### 모델 확인\n",
        "\n",
        "모델의 구조를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReAD0n6MsFK-"
      },
      "outputs": [],
      "source": [
        "model = MPGregression(input_dims=normed_train_data.shape[-1])\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt6W50qGsJAL"
      },
      "source": [
        "모델을 한번 실행해 보죠. 훈련 세트에서 `10` 샘플을 하나의 배치로 만들어 모델 결과를 호출해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch = normed_train_data[:10]\n",
        "model.eval()\n",
        "pred = model.forward(torch.tensor(example_batch.values, dtype=torch.float32))"
      ],
      "metadata": {
        "id": "0cbQNvCfc5TU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "vUIPdtqyc6CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlM8KrSOsaYo"
      },
      "source": [
        "제대로 작동하는 것 같네요. 결괏값의 크기와 타입이 기대했던 대로입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-qWCsh6DlyH"
      },
      "source": [
        "### 모델 훈련\n",
        "\n",
        "이 모델을 1,000번의 에포크(epoch) 동안 훈련합니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "train_mse = []\n",
        "train_mae = []\n",
        "val_mse = []\n",
        "val_mae = []\n",
        "loss_fn = nn.MSELoss()\n",
        "model = model = MPGregression(input_dims=normed_train_data.shape[-1]).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    t_mse, t_mae = train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
        "    print(f\"Train Error: \\n Avg loss: {t_mse.item():>8f} \\n\")\n",
        "    v_mse, v_mae = test_epoch(test_dataloader, model, loss_fn)\n",
        "    print(f\"Validation Error: \\n Avg loss: {v_mse.item():>8f} \\n\")\n",
        "    train_mse.append(t_mse.item()); train_mae.append(t_mae.item())\n",
        "    val_mse.append(v_mse.item()); val_mae.append(v_mae.item())\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "scY_96hjdmTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"mean squared error\")\n",
        "plt.plot(list(range(1,len(train_mse)+1)), train_mse, label='train loss')\n",
        "plt.plot(list(range(1,len(val_mse)+1)), val_mse, label='val loss')\n",
        "plt.ylim([0,20])\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"mean absolute error\")\n",
        "plt.plot(list(range(1,len(train_mae)+1)), train_mae, label='train loss')\n",
        "plt.plot(list(range(1,len(val_mae)+1)), val_mae, label='val loss')\n",
        "plt.ylim([0,20])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T8khO4N5l5cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 그래프를 보면 수 백번 에포크를 진행한 이후에는 모델이 거의 향상되지 않는 것 같습니다. 검증 점수가 향상되지 않으면 자동으로 훈련을 멈추도록 만들어 보죠. 에포크마다 훈련 상태를 점검하기 위해 EarlyStopping 클래스를 만들어 사용하겠습니다. 지정된 에포크 횟수 동안 성능 향상이 없으면 자동으로 훈련이 멈춥니다.\n",
        "\n",
        "또한 시간에 따라 모델의 성능이 오히려 악화될 수 있으므로, 검증데이터 상 가장 좋은 성능을 보여준 모델의 체크포인트를 저장할 필요가 있습니다. EarlyStopping 내부에 best 모델을 저장하도록 구현했했습니다."
      ],
      "metadata": {
        "id": "n2CeaJ-wmaOR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sD7qHCmNIOY0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
        "                            Default: 7\n",
        "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
        "                            Default: False\n",
        "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
        "                            Default: 0\n",
        "            path (str): checkpoint저장 경로\n",
        "                            Default: 'checkpoint.pt'\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "train_mse = [];train_mae=[]\n",
        "val_mse = [];val_mae=[]\n",
        "loss_fn = nn.MSELoss()\n",
        "model = model = MPGregression(input_dims=normed_train_data.shape[-1]).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "ckpt_path = \"./\"\n",
        "early_stopping = EarlyStopping(patience = 10, verbose = True, path=os.path.join(ckpt_path ,'best_checkpoint.pt'))\n",
        "\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    t_mse, t_mae = train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
        "    print(f\"Train Error: \\n Avg loss: {t_mse.item():>8f} \\n\")\n",
        "    v_mse, v_mae = test_epoch(test_dataloader, model, loss_fn)\n",
        "    print(f\"Validation Error: \\n Avg loss: {v_mse.item():>8f} \\n\")\n",
        "\n",
        "    early_stopping(v_mse.item(), model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "    train_mse.append(t_mse.item()); train_mae.append(t_mae.item())\n",
        "    val_mse.append(v_mse.item()); val_mae.append(v_mae.item())\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "dfm0TSgunwQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQm3pc0FYPQB"
      },
      "source": [
        "저장된 학습로그를 사용해 모델의 훈련 과정을 시각화해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"mean squared error\")\n",
        "plt.plot(list(range(1,len(train_mse)+1)), train_mse, label='train')\n",
        "plt.plot(list(range(1,len(val_mse)+1)), val_mse, label='val')\n",
        "plt.ylim([0,20])\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"mean absolute error\")\n",
        "plt.plot(list(range(1,len(train_mae)+1)), train_mae, label='train')\n",
        "plt.plot(list(range(1,len(val_mae)+1)), val_mae, label='val')\n",
        "plt.ylim([0,20])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SazFVzt2oTGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CEkE4urwsANj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3St8-DmrX8P4"
      },
      "source": [
        "이 그래프를 보면 검증 세트의 평균 오차가 약 +/- 2 MPG입니다. 좋은 결과인가요? 이에 대한 평가는 여러분에게 맡기겠습니다.\n",
        "\n",
        "모델을 훈련할 때 사용하지 않았던 **테스트 세트**에서 모델의 성능을 확인해 보죠. 이를 통해 모델이 실전에 투입되었을 때 모델의 성능을 짐작할 수 있습니다:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft603OzXuEZC"
      },
      "source": [
        "## 예측\n",
        "\n",
        "마지막으로 테스트 세트에 있는 샘플을 사용해 MPG 값을 예측해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MPGregression(input_dims=9)\n",
        "model.load_state_dict(torch.load(\"./best_checkpoint.pt\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "7d3rtcJ1xbm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model.forward(torch.tensor(normed_test_data.values, dtype=torch.float32)).flatten().detach().numpy()"
      ],
      "metadata": {
        "id": "5o1DAk8uxaXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xe7RXH3N3CWU"
      },
      "outputs": [],
      "source": [
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU1jBsRLaCeY"
      },
      "source": [
        "모델이 꽤 잘 예측한 것 같습니다. 오차의 분포를 살펴 보죠."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-OHX4DiXd8x"
      },
      "outputs": [],
      "source": [
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [MPG]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PkzkjFkaCed"
      },
      "source": [
        "가우시안 분포가 아니지만 아마도 훈련 샘플의 수가 매우 작기 때문일 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgGQuV-yqYZH"
      },
      "source": [
        "## 결론\n",
        "\n",
        "이 노트북은 회귀 문제를 위한 기법을 소개합니다.\n",
        "\n",
        "* 평균 제곱 오차(MSE)는 회귀 문제에서 자주 사용하는 손실 함수입니다(분류 문제에서 사용하는 손실 함수와 다릅니다).\n",
        "* 비슷하게 회귀에서 사용되는 평가 지표도 분류와 다릅니다. 많이 사용하는 회귀 지표는 평균 절댓값 오차(MAE)입니다.\n",
        "* 수치 입력 데이터의 특성이 여러 가지 범위를 가질 때 동일한 범위가 되도록 각 특성의 스케일을 독립적으로 조정해야 합니다.\n",
        "* 훈련 데이터가 많지 않다면 과대적합을 피하기 위해 은닉층의 개수가 적은 소규모 네트워크를 선택하는 방법이 좋습니다.\n",
        "* 조기 종료(Early stopping)은 과대적합을 방지하기 위한 좋은 방법입니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}